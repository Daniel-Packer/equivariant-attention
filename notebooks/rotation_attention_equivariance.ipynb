{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cis/home/dpacker/my_documents/equivariant-attention\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import rotation_attention, positional_encodings, equivariance\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps, animation\n",
    "rng = jax.random.PRNGKey(seed=1)\n",
    "rngs = jax.random.split(rng, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "n_keys = 5\n",
    "n_group_samples = 15\n",
    "d = 2\n",
    "\n",
    "X_train = positional_encodings.uniform_ball_samples(rngs[0], n_samples, d = d, r = 1.)\n",
    "X_train_encoded = positional_encodings.positional_encoding(X_train, method = \"stereographic\")\n",
    "\n",
    "X_test = positional_encodings.uniform_ball_samples(rngs[1], n_samples, d = d, r = 1.)\n",
    "X_test_encoded = positional_encodings.positional_encoding(X_test, method = \"stereographic\")\n",
    "\n",
    "rotation = rotation_attention.group_samples(360, 0)[113]\n",
    "f = lambda x : rotation @ x * jnp.linalg.norm(x)\n",
    "\n",
    "Y_train = jax.vmap(f)(X_train)\n",
    "noise = jax.random.normal(rngs[2], shape=Y_train.shape) * 0.1\n",
    "Y_test = jax.vmap(f)(X_test)\n",
    "\n",
    "stereographic_encoding = lambda v: positional_encodings.positional_encoding(\n",
    "    v, method=\"stereographic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cf9ec1955f4f9194c3e231a8bbf7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n_epochs = 5000\n",
    "\n",
    "keys_hist, values_hist, key_reps, value_reps, betas_hist = rotation_attention.train(\n",
    "    rngs[3],\n",
    "    X_train,\n",
    "    stereographic_encoding,\n",
    "    n_keys,\n",
    "    n_group_samples,\n",
    "    n_epochs=n_epochs,\n",
    "    lr=1.0,\n",
    "    Y_train=Y_train + noise, \n",
    "    verbose=True,\n",
    "    # init_values=init_values,\n",
    "    # init_keys=init_keys,\n",
    "    init_beta = 1.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda v: rotation_attention.call_fn(v, keys_hist[-1], key_reps, values_hist[-1], value_reps, betas_hist[-1])\n",
    "\n",
    "domain_reps = rotation_attention.group_samples(1_000, 1)\n",
    "codomain_reps = rotation_attention.group_samples(1_000, 0)\n",
    "\n",
    "equivariance.batched_check_equivariance(func, stereographic_encoding(X_test), domain_reps, codomain_reps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
